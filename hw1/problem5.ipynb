{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\n#Test the convolutions with 1 image, to put in the article\\n# Test\\ndf_train = pd.read_csv('train.csv')\\nimg = df_train.iloc[40,:].values[1:]\\nimg = np.reshape(img,(28,28))\\nplt.imshow(img, cmap='gray')\\nplt.show()\\nprint(img.shape)\\nplt.savefig('images/original_image.png', format='png', dpi=1200)\\n\\n# Test with a convolution of 16 filters of size 3x3\\nmy_conv = ConvolutionLayer(32,3)\\noutput = my_conv.forward_prop(img)\\n# See the dimensions of the output volume, they follow the usual formula\\nprint(output.shape)\\n\\n# Plot 16th volume after the convolution\\nplt.imshow(output[:,:,15], cmap='gray')\\nplt.show()\\nplt.savefig('images/image_convolved.png', format='png', dpi=1200)\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author: Riccardo Andreoni\n",
    "Title: Implementation of Convolutional Neural Network from scratch.\n",
    "File: utils.py\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class ConvolutionLayer:\n",
    "    def __init__(self, kernel_num, kernel_size):\n",
    "        \"\"\"\n",
    "        Constructor takes as input the number of kernels and their size. I assume only squared filters of size kernel_size x kernel_size\n",
    "        \"\"\"\n",
    "        self.kernel_num = kernel_num\n",
    "        self.kernel_size = kernel_size\n",
    "        # Generate random filters of shape (kernel_num, kernel_size, kernel_size). Divide by kernel_size^2 for weight normalization\n",
    "        self.kernels = np.random.randn(kernel_num, kernel_size, kernel_size) / (kernel_size**2)\n",
    "\n",
    "    def patches_generator(self, image):\n",
    "        \"\"\"\n",
    "        Divide the input image in patches to be used during convolution.\n",
    "        Yields the tuples containing the patches and their coordinates.\n",
    "        \"\"\"\n",
    "        # Extract image height and width\n",
    "        image_h, image_w = image.shape\n",
    "        self.image = image\n",
    "        # The number of patches, given a fxf filter is h-f+1 for height and w-f+1 for width\n",
    "        for h in range(image_h-self.kernel_size+1):\n",
    "            for w in range(image_w-self.kernel_size+1):\n",
    "                patch = image[h:(h+self.kernel_size), w:(w+self.kernel_size)]\n",
    "                yield patch, h, w\n",
    "    \n",
    "    def forward_prop(self, image):\n",
    "        \"\"\"\n",
    "        Perform forward propagation for the convolutional layer.\n",
    "        \"\"\"\n",
    "        # Extract image height and width\n",
    "        image_h, image_w = image.shape\n",
    "        # Initialize the convolution output volume of the correct size\n",
    "        convolution_output = np.zeros((image_h-self.kernel_size+1, image_w-self.kernel_size+1, self.kernel_num))\n",
    "        # Unpack the generator\n",
    "        for patch, h, w in self.patches_generator(image):\n",
    "            # Perform convolution for each patch\n",
    "            convolution_output[h,w] = np.sum(patch*self.kernels, axis=(1,2))\n",
    "        return convolution_output\n",
    "    \n",
    "    def back_prop(self, dE_dY, alpha):\n",
    "        \"\"\"\n",
    "        Takes the gradient of the loss function with respect to the output and computes the gradients of the loss function with respect\n",
    "        to the kernels' weights.\n",
    "        dE_dY comes from the following layer, typically max pooling layer.\n",
    "        It updates the kernels' weights\n",
    "        \"\"\"\n",
    "        # Initialize gradient of the loss function with respect to the kernel weights\n",
    "        dE_dk = np.zeros(self.kernels.shape)\n",
    "        for patch, h, w in self.patches_generator(self.image):\n",
    "            for f in range(self.kernel_num):\n",
    "                dE_dk[f] += patch * dE_dY[h, w, f]\n",
    "        # Update the parameters\n",
    "        self.kernels -= alpha*dE_dk\n",
    "        return dE_dk\n",
    "\n",
    "class MaxPoolingLayer:\n",
    "    def __init__(self, kernel_size):\n",
    "        \"\"\"\n",
    "        Constructor takes as input the size of the kernel\n",
    "        \"\"\"\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "    def patches_generator(self, image):\n",
    "        \"\"\"\n",
    "        Divide the input image in patches to be used during pooling.\n",
    "        Yields the tuples containing the patches and their coordinates.\n",
    "        \"\"\"\n",
    "        # Compute the ouput size\n",
    "        output_h = image.shape[0] // self.kernel_size\n",
    "        output_w = image.shape[1] // self.kernel_size\n",
    "        self.image = image\n",
    "\n",
    "        for h in range(output_h):\n",
    "            for w in range(output_w):\n",
    "                patch = image[(h*self.kernel_size):(h*self.kernel_size+self.kernel_size), (w*self.kernel_size):(w*self.kernel_size+self.kernel_size)]\n",
    "                yield patch, h, w\n",
    "\n",
    "    def forward_prop(self, image):\n",
    "        image_h, image_w, num_kernels = image.shape\n",
    "        max_pooling_output = np.zeros((image_h//self.kernel_size, image_w//self.kernel_size, num_kernels))\n",
    "        for patch, h, w in self.patches_generator(image):\n",
    "            max_pooling_output[h,w] = np.amax(patch, axis=(0,1))\n",
    "        return max_pooling_output\n",
    "\n",
    "    #Starts back prop for the convolutional layer. He does not update the weights of the filter.\n",
    "    def back_prop(self, dE_dY):\n",
    "        \"\"\"\n",
    "        Takes the gradient of the loss function with respect to the output and computes the gradients of the loss function with respect\n",
    "        to the kernels' weights.\n",
    "        dE_dY comes from the following layer, typically softmax.\n",
    "        There are no weights to update, but the output is needed to update the weights of the convolutional layer.\n",
    "        \"\"\"\n",
    "        dE_dk = np.zeros(self.image.shape)\n",
    "        for patch,h,w in self.patches_generator(self.image):\n",
    "            image_h, image_w, num_kernels = patch.shape\n",
    "            max_val = np.amax(patch, axis=(0,1))\n",
    "\n",
    "            for idx_h in range(image_h):\n",
    "                for idx_w in range(image_w):\n",
    "                    for idx_k in range(num_kernels):\n",
    "                        if patch[idx_h,idx_w,idx_k] == max_val[idx_k]:\n",
    "                            dE_dk[h*self.kernel_size+idx_h, w*self.kernel_size+idx_w, idx_k] = dE_dY[h,w,idx_k]\n",
    "        return dE_dk\n",
    "\n",
    "class SoftmaxLayer:\n",
    "    \"\"\"\n",
    "    Takes the volume coming from convolutional & pooling layers. It flattens it and it uses it in the next layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_units, output_units):\n",
    "        # Initiallize weights and biases\n",
    "        self.weight = np.random.randn(input_units, output_units)/input_units\n",
    "        self.bias = np.zeros(output_units)\n",
    "\n",
    "    def forward_prop(self, image):\n",
    "        self.original_shape = image.shape # stored for backprop\n",
    "        # Flatten the image\n",
    "        image_flattened = image.flatten()\n",
    "        self.flattened_input = image_flattened # stored for backprop\n",
    "        # Perform matrix multiplication and add bias\n",
    "        first_output = np.dot(image_flattened, self.weight) + self.bias\n",
    "        self.output = first_output\n",
    "        # Apply softmax activation\n",
    "        softmax_output = np.exp(first_output) / np.sum(np.exp(first_output), axis=0)\n",
    "        return softmax_output\n",
    "\n",
    "    #Back prop for the softmax layer\n",
    "    def back_prop(self, dE_dY, alpha):\n",
    "        for i, gradient in enumerate(dE_dY):\n",
    "            if gradient == 0:\n",
    "                continue\n",
    "            transformation_eq = np.exp(self.output)\n",
    "            S_total = np.sum(transformation_eq)\n",
    "\n",
    "            # Compute gradients with respect to output (Z)\n",
    "            dY_dZ = -transformation_eq[i]*transformation_eq / (S_total**2)\n",
    "            dY_dZ[i] = transformation_eq[i]*(S_total - transformation_eq[i]) / (S_total**2)\n",
    "\n",
    "            # Compute gradients of output Z with respect to weight, bias, input\n",
    "            dZ_dw = self.flattened_input\n",
    "            dZ_db = 1\n",
    "            dZ_dX = self.weight\n",
    "\n",
    "            # Gradient of loss with respect ot output\n",
    "            dE_dZ = gradient * dY_dZ\n",
    "\n",
    "            # Gradient of loss with respect to weight, bias, input\n",
    "            dE_dw = dZ_dw[np.newaxis].T @ dE_dZ[np.newaxis]\n",
    "            dE_db = dE_dZ * dZ_db\n",
    "            dE_dX = dZ_dX @ dE_dZ\n",
    "\n",
    "            # Update parameters\n",
    "            self.weight -= alpha*dE_dw\n",
    "            self.bias -= alpha*dE_db\n",
    "\n",
    "            return dE_dX.reshape(self.original_shape)\n",
    "\n",
    "def CNN_forward(image, label, layers):\n",
    "    output = image/255.\n",
    "    for layer in layers:\n",
    "        output = layer.forward_prop(output)\n",
    "    # Compute loss (cross-entropy) and accuracy\n",
    "    loss = -np.log(output[label])\n",
    "    accuracy = 1 if np.argmax(output) == label else 0\n",
    "    return output, loss, accuracy\n",
    "\n",
    "#Starts the back prop algorithm\n",
    "def CNN_backprop(gradient, layers, alpha=0.05):\n",
    "    grad_back = gradient\n",
    "    for layer in layers[::-1]:\n",
    "        if type(layer) in [ConvolutionLayer, SoftmaxLayer]:\n",
    "            grad_back = layer.back_prop(grad_back, alpha)\n",
    "        elif type(layer) == MaxPoolingLayer:\n",
    "            grad_back = layer.back_prop(grad_back)\n",
    "    return grad_back\n",
    "\n",
    "\n",
    "def CNN_training(image, label, layers, alpha=0.05):\n",
    "    # Forward step\n",
    "    output, loss, accuracy = CNN_forward(image, label, layers)\n",
    "\n",
    "    # Initial gradient\n",
    "    gradient = np.zeros(10)\n",
    "    gradient[label] = -1/output[label]\n",
    "\n",
    "    # Backprop step\n",
    "    gradient_back = CNN_backprop(gradient, layers, alpha)\n",
    "\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#Test the convolutions with 1 image, to put in the article\n",
    "# Test\n",
    "df_train = pd.read_csv('train.csv')\n",
    "img = df_train.iloc[40,:].values[1:]\n",
    "img = np.reshape(img,(28,28))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "print(img.shape)\n",
    "plt.savefig('images/original_image.png', format='png', dpi=1200)\n",
    "\n",
    "# Test with a convolution of 16 filters of size 3x3\n",
    "my_conv = ConvolutionLayer(32,3)\n",
    "output = my_conv.forward_prop(img)\n",
    "# See the dimensions of the output volume, they follow the usual formula\n",
    "print(output.shape)\n",
    "\n",
    "# Plot 16th volume after the convolution\n",
    "plt.imshow(output[:,:,15], cmap='gray')\n",
    "plt.show()\n",
    "plt.savefig('images/image_convolved.png', format='png', dpi=1200)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 ->\n",
      "Step 1. For the last 100 steps: average loss 0.0, accuracy 0\n",
      "Step 101. For the last 100 steps: average loss 1.7802698087376327, accuracy 45\n",
      "Step 201. For the last 100 steps: average loss 1.0893162145443671, accuracy 65\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/erikconnerty/Code/CSCE-790/hw1/problem5.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/erikconnerty/Code/CSCE-790/hw1/problem5.ipynb#W1sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m       accuracy \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m accuracy_1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/erikconnerty/Code/CSCE-790/hw1/problem5.ipynb#W1sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/erikconnerty/Code/CSCE-790/hw1/problem5.ipynb#W1sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m   main()\n",
      "\u001b[1;32m/Users/erikconnerty/Code/CSCE-790/hw1/problem5.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/erikconnerty/Code/CSCE-790/hw1/problem5.ipynb#W1sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m   loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/erikconnerty/Code/CSCE-790/hw1/problem5.ipynb#W1sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m   accuracy \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/erikconnerty/Code/CSCE-790/hw1/problem5.ipynb#W1sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m loss_1, accuracy_1 \u001b[39m=\u001b[39m CNN_training(image, label, layers)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/erikconnerty/Code/CSCE-790/hw1/problem5.ipynb#W1sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/erikconnerty/Code/CSCE-790/hw1/problem5.ipynb#W1sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m accuracy \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m accuracy_1\n",
      "\u001b[1;32m/Users/erikconnerty/Code/CSCE-790/hw1/problem5.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/erikconnerty/Code/CSCE-790/hw1/problem5.ipynb#W1sZmlsZQ%3D%3D?line=186'>187</a>\u001b[0m gradient[label] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\u001b[39m/\u001b[39moutput[label]\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/erikconnerty/Code/CSCE-790/hw1/problem5.ipynb#W1sZmlsZQ%3D%3D?line=188'>189</a>\u001b[0m \u001b[39m# Backprop step\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/erikconnerty/Code/CSCE-790/hw1/problem5.ipynb#W1sZmlsZQ%3D%3D?line=189'>190</a>\u001b[0m gradient_back \u001b[39m=\u001b[39m CNN_backprop(gradient, layers, alpha)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/erikconnerty/Code/CSCE-790/hw1/problem5.ipynb#W1sZmlsZQ%3D%3D?line=191'>192</a>\u001b[0m \u001b[39mreturn\u001b[39;00m loss, accuracy\n",
      "\u001b[1;32m/Users/erikconnerty/Code/CSCE-790/hw1/problem5.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/erikconnerty/Code/CSCE-790/hw1/problem5.ipynb#W1sZmlsZQ%3D%3D?line=172'>173</a>\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m layers[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]:\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/erikconnerty/Code/CSCE-790/hw1/problem5.ipynb#W1sZmlsZQ%3D%3D?line=173'>174</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(layer) \u001b[39min\u001b[39;00m [ConvolutionLayer, SoftmaxLayer]:\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/erikconnerty/Code/CSCE-790/hw1/problem5.ipynb#W1sZmlsZQ%3D%3D?line=174'>175</a>\u001b[0m         grad_back \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mback_prop(grad_back, alpha)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/erikconnerty/Code/CSCE-790/hw1/problem5.ipynb#W1sZmlsZQ%3D%3D?line=175'>176</a>\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(layer) \u001b[39m==\u001b[39m MaxPoolingLayer:\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/erikconnerty/Code/CSCE-790/hw1/problem5.ipynb#W1sZmlsZQ%3D%3D?line=176'>177</a>\u001b[0m         grad_back \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mback_prop(grad_back)\n",
      "\u001b[1;32m/Users/erikconnerty/Code/CSCE-790/hw1/problem5.ipynb Cell 2\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/erikconnerty/Code/CSCE-790/hw1/problem5.ipynb#W1sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39mfor\u001b[39;00m patch, h, w \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatches_generator(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/erikconnerty/Code/CSCE-790/hw1/problem5.ipynb#W1sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_num):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/erikconnerty/Code/CSCE-790/hw1/problem5.ipynb#W1sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m         dE_dk[f] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m patch \u001b[39m*\u001b[39m dE_dY[h, w, f]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/erikconnerty/Code/CSCE-790/hw1/problem5.ipynb#W1sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39m# Update the parameters\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/erikconnerty/Code/CSCE-790/hw1/problem5.ipynb#W1sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernels \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m alpha\u001b[39m*\u001b[39mdE_dk\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author: Riccardo Andreoni\n",
    "Title: Implementation of Convolutional Neural Network from scratch.\n",
    "File: main.py\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def main():\n",
    "  # Load training data\n",
    "  (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "  X_train = X_train[:5000]\n",
    "  y_train = y_train[:5000]\n",
    "\n",
    "  # Define the network\n",
    "  layers = [\n",
    "    #He does not use a non linear activation function after the convolutional layer\n",
    "    ConvolutionLayer(16,3), # layer with 8 3x3 filters, output (26,26,16)\n",
    "    MaxPoolingLayer(2), # pooling layer 2x2, output (13,13,16)\n",
    "    SoftmaxLayer(13*13*16, 10) # softmax layer with 13*13*16 input and 10 output\n",
    "    ] \n",
    "\n",
    "  #Loop through the data 4 times\n",
    "  for epoch in range(4):\n",
    "    print('Epoch {} ->'.format(epoch+1))\n",
    "    # Shuffle training data\n",
    "    permutation = np.random.permutation(len(X_train))\n",
    "    X_train = X_train[permutation]\n",
    "    y_train = y_train[permutation]\n",
    "    # Training the CNN\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    #Loop through each image and train for each one\n",
    "    for i, (image, label) in enumerate(zip(X_train, y_train)):\n",
    "      if i % 100 == 0: # Every 100 examples\n",
    "        print(\"Step {}. For the last 100 steps: average loss {}, accuracy {}\".format(i+1, loss/100, accuracy))\n",
    "        loss = 0\n",
    "        accuracy = 0\n",
    "      loss_1, accuracy_1 = CNN_training(image, label, layers)\n",
    "      loss += loss_1\n",
    "      accuracy += accuracy_1\n",
    "  \n",
    "  \n",
    "if __name__ == '__main__':\n",
    "  main()\n",
    "  \n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
